{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6519849",
   "metadata": {},
   "source": [
    "# [과제1] 교제 Part4 작물 잎 사진으로 질병 분류하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0938d86",
   "metadata": {},
   "source": [
    "## 개요\n",
    "\n",
    "- 이미지 분류 모델을 활용하여 작물 잎 사진의 종류와 질병 유무를 분류\n",
    "- Transfer Learning, Convolutional Neural Network\n",
    "- 총 데이터 수: 40,000개"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ee151f",
   "metadata": {},
   "source": [
    "## 데이터 설명\n",
    "\n",
    "- Apple_Apple_scab\n",
    "- Apple_Black_rot\n",
    "- Apple_Cedar_apple\n",
    "- Apple_healthy: ---질병 없는 사과\n",
    "- Cherry_Powdery\n",
    "- Cherry_healthy: **질병 없는 체리**\n",
    "- Corn_Cercospora\n",
    "- Corn_Common_rust\n",
    "- Corn_Northern_Leaf\n",
    "- Corn_healthy: **질병 없는 옥수수**\n",
    "- Grape_Black_rot\n",
    "- Grape_Esca\n",
    "- Grape_Leaf_blight\n",
    "- Grape_healthy: **질병 없는 포도**\n",
    "- Peach_Bacterial_spot\n",
    "- Peach_healthy: **질병 없는 복숭아**\n",
    "- Pepper_Bacterial_spot\n",
    "- Pepper_bell_healthy: **질병 없는 후추**\n",
    "- Potato_Early_blight\n",
    "- Potato_Late_blight\n",
    "- Potato_healthy: **질병 없는 감자**\n",
    "- Strawberry_healthy: **질병 없는 딸기**\n",
    "- Strawberry_scorch\n",
    "- Tomato_Bacterial_spot\n",
    "- Tomato_Early_blight\n",
    "- Tomato_Late_blight\n",
    "- Tomato_Leaf_Mold\n",
    "- Tomato_Septoria_leaf\n",
    "- Tomato_Spider_mites\n",
    "- Tomato_Target_Spot\n",
    "- Tomato_mosaic_virus\n",
    "- Tomato_Yellow_Leaf\n",
    "- Tomato_healthy: **질병 없는 토마토**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e50a57",
   "metadata": {},
   "source": [
    "## 데이터 분할을 위한 폴더 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "694bb2a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-27T06:50:58.979713Z",
     "start_time": "2022-07-27T06:50:58.950475Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# 원본 데이터셋이 위치한 경로\n",
    "original_dataset_dir = '.datasets'\n",
    "# os.listdir() 메서드는 해당 경로 하위에 있는 모든 폴더의 목록을 가져옴\n",
    "classes_list = os.listdir(original_dataset_dir)\n",
    "\n",
    "# 나눈 데이터를 저장할 폴더를 생성\n",
    "base_dir = '.splitted'\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "# 분리 후에 각 데이터를 저장할 하위 폴더 train, val, test를 생성\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir, 'val')\n",
    "os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "# train, validation, test 폴더 하위에 각각 클래스 목록 폴더를 생성\n",
    "for clss in classes_list:\n",
    "    os.mkdir(os.path.join(train_dir, clss))\n",
    "    os.mkdir(os.path.join(validation_dir, clss))\n",
    "    os.mkdir(os.path.join(test_dir, clss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f30950f",
   "metadata": {},
   "source": [
    "## 데이터 분할과 클래스별 데이터 수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75433e97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-27T06:51:12.539265Z",
     "start_time": "2022-07-27T06:50:58.981080Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size( Apple___Apple_scab ): 378\n",
      "Validation size( Apple___Apple_scab ): 126\n",
      "Test size( Apple___Apple_scab ): 126\n",
      "Train size( Apple___Black_rot ): 372\n",
      "Validation size( Apple___Black_rot ): 124\n",
      "Test size( Apple___Black_rot ): 124\n",
      "Train size( Apple___Cedar_apple_rust ): 165\n",
      "Validation size( Apple___Cedar_apple_rust ): 55\n",
      "Test size( Apple___Cedar_apple_rust ): 55\n",
      "Train size( Apple___healthy ): 987\n",
      "Validation size( Apple___healthy ): 329\n",
      "Test size( Apple___healthy ): 329\n",
      "Train size( Cherry___healthy ): 512\n",
      "Validation size( Cherry___healthy ): 170\n",
      "Test size( Cherry___healthy ): 170\n",
      "Train size( Cherry___Powdery_mildew ): 631\n",
      "Validation size( Cherry___Powdery_mildew ): 210\n",
      "Test size( Cherry___Powdery_mildew ): 210\n",
      "Train size( Corn___Cercospora_leaf_spot Gray_leaf_spot ): 307\n",
      "Validation size( Corn___Cercospora_leaf_spot Gray_leaf_spot ): 102\n",
      "Test size( Corn___Cercospora_leaf_spot Gray_leaf_spot ): 102\n",
      "Train size( Corn___Common_rust ): 715\n",
      "Validation size( Corn___Common_rust ): 238\n",
      "Test size( Corn___Common_rust ): 238\n",
      "Train size( Corn___healthy ): 697\n",
      "Validation size( Corn___healthy ): 232\n",
      "Test size( Corn___healthy ): 232\n",
      "Train size( Corn___Northern_Leaf_Blight ): 591\n",
      "Validation size( Corn___Northern_Leaf_Blight ): 197\n",
      "Test size( Corn___Northern_Leaf_Blight ): 197\n",
      "Train size( Grape___Black_rot ): 708\n",
      "Validation size( Grape___Black_rot ): 236\n",
      "Test size( Grape___Black_rot ): 236\n",
      "Train size( Grape___Esca_(Black_Measles) ): 829\n",
      "Validation size( Grape___Esca_(Black_Measles) ): 276\n",
      "Test size( Grape___Esca_(Black_Measles) ): 276\n",
      "Train size( Grape___healthy ): 253\n",
      "Validation size( Grape___healthy ): 84\n",
      "Test size( Grape___healthy ): 84\n",
      "Train size( Grape___Leaf_blight_(Isariopsis_Leaf_Spot) ): 645\n",
      "Validation size( Grape___Leaf_blight_(Isariopsis_Leaf_Spot) ): 215\n",
      "Test size( Grape___Leaf_blight_(Isariopsis_Leaf_Spot) ): 215\n",
      "Train size( Peach___Bacterial_spot ): 1378\n",
      "Validation size( Peach___Bacterial_spot ): 459\n",
      "Test size( Peach___Bacterial_spot ): 459\n",
      "Train size( Peach___healthy ): 216\n",
      "Validation size( Peach___healthy ): 72\n",
      "Test size( Peach___healthy ): 72\n",
      "Train size( Pepper,_bell___Bacterial_spot ): 598\n",
      "Validation size( Pepper,_bell___Bacterial_spot ): 199\n",
      "Test size( Pepper,_bell___Bacterial_spot ): 199\n",
      "Train size( Pepper,_bell___healthy ): 886\n",
      "Validation size( Pepper,_bell___healthy ): 295\n",
      "Test size( Pepper,_bell___healthy ): 295\n",
      "Train size( Potato___Early_blight ): 600\n",
      "Validation size( Potato___Early_blight ): 200\n",
      "Test size( Potato___Early_blight ): 200\n",
      "Train size( Potato___healthy ): 91\n",
      "Validation size( Potato___healthy ): 30\n",
      "Test size( Potato___healthy ): 30\n",
      "Train size( Potato___Late_blight ): 600\n",
      "Validation size( Potato___Late_blight ): 200\n",
      "Test size( Potato___Late_blight ): 200\n",
      "Train size( Strawberry___healthy ): 273\n",
      "Validation size( Strawberry___healthy ): 91\n",
      "Test size( Strawberry___healthy ): 91\n",
      "Train size( Strawberry___Leaf_scorch ): 665\n",
      "Validation size( Strawberry___Leaf_scorch ): 221\n",
      "Test size( Strawberry___Leaf_scorch ): 221\n",
      "Train size( Tomato___Bacterial_spot ): 1276\n",
      "Validation size( Tomato___Bacterial_spot ): 425\n",
      "Test size( Tomato___Bacterial_spot ): 425\n",
      "Train size( Tomato___Early_blight ): 600\n",
      "Validation size( Tomato___Early_blight ): 200\n",
      "Test size( Tomato___Early_blight ): 200\n",
      "Train size( Tomato___healthy ): 954\n",
      "Validation size( Tomato___healthy ): 318\n",
      "Test size( Tomato___healthy ): 318\n",
      "Train size( Tomato___Late_blight ): 1145\n",
      "Validation size( Tomato___Late_blight ): 381\n",
      "Test size( Tomato___Late_blight ): 381\n",
      "Train size( Tomato___Leaf_Mold ): 571\n",
      "Validation size( Tomato___Leaf_Mold ): 190\n",
      "Test size( Tomato___Leaf_Mold ): 190\n",
      "Train size( Tomato___Septoria_leaf_spot ): 1062\n",
      "Validation size( Tomato___Septoria_leaf_spot ): 354\n",
      "Test size( Tomato___Septoria_leaf_spot ): 354\n",
      "Train size( Tomato___Spider_mites Two-spotted_spider_mite ): 1005\n",
      "Validation size( Tomato___Spider_mites Two-spotted_spider_mite ): 335\n",
      "Test size( Tomato___Spider_mites Two-spotted_spider_mite ): 335\n",
      "Train size( Tomato___Target_Spot ): 842\n",
      "Validation size( Tomato___Target_Spot ): 280\n",
      "Test size( Tomato___Target_Spot ): 280\n",
      "Train size( Tomato___Tomato_mosaic_virus ): 223\n",
      "Validation size( Tomato___Tomato_mosaic_virus ): 74\n",
      "Test size( Tomato___Tomato_mosaic_virus ): 74\n",
      "Train size( Tomato___Tomato_Yellow_Leaf_Curl_Virus ): 3214\n",
      "Validation size( Tomato___Tomato_Yellow_Leaf_Curl_Virus ): 1071\n",
      "Test size( Tomato___Tomato_Yellow_Leaf_Curl_Virus ): 1071\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# for 문을 통해 모든 클래스에 대한 작업을 반복\n",
    "for clss in classes_list:\n",
    "    # path 위치에 존재하는 모든 이미지 파일의 목록을 변수 fnames에 저장\n",
    "    path = os.path.join(original_dataset_dir, clss)\n",
    "    fnames = os.listdir(path)\n",
    "\n",
    "    # Train, Validation, Test 데이터의 비율을 지정(6:2:2)\n",
    "    train_size = math.floor(len(fnames) * 0.6)\n",
    "    validation_size = math.floor(len(fnames) * 0.2)\n",
    "    test_size = math.floor(len(fnames) * 0.2)\n",
    "\n",
    "    # Train 데이터에 해당하는 파일의 이름을 train_fname에 저장\n",
    "    train_fnames = fnames[:train_size]\n",
    "    print('Train size(', clss, '):', len(train_fnames))\n",
    "    # 모든 Train 데이터에 대해 for문의 내용을 반복\n",
    "    for fname in train_fnames:\n",
    "        # 복사할 원본 파일의 경로\n",
    "        src = os.path.join(path, fname)\n",
    "        # 복사한 후 저장할 파일의 경로\n",
    "        dst = os.path.join(os.path.join(train_dir, clss), fname)\n",
    "        # src의 경로에 해당하는 파일을 dst 경로에 저장\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    # Validation 데이터에 대해 위의 코드 반복\n",
    "    validation_fnames = fnames[train_size:(train_size + validation_size)]\n",
    "    print('Validation size(', clss, '):', len(validation_fnames))\n",
    "    for fname in validation_fnames:\n",
    "        src = os.path.join(path, fname)\n",
    "        dst = os.path.join(os.path.join(validation_dir, clss), fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    # Test 데이터에 대해 위의 코드 반복\n",
    "    test_fnames = fnames[(train_size +\n",
    "                          validation_size):(train_size + validation_size +\n",
    "                                            test_size)]\n",
    "    print('Test size(', clss, '):', len(test_fnames))\n",
    "    for fname in test_fnames:\n",
    "        src = os.path.join(path, fname)\n",
    "        dst = os.path.join(os.path.join(test_dir, clss), fname)\n",
    "        shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3519191",
   "metadata": {},
   "source": [
    "## 베이스라인 모델 학습을 위한 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62f411f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-27T06:51:13.442809Z",
     "start_time": "2022-07-27T06:51:12.541252Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\miniconda3\\envs\\gpu2.6\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\HP\\miniconda3\\envs\\gpu2.6\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 현재 사용 중인 환경에서 GPU를 사용할 수 있는 지 확인\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "# GPU 사용 가능 하면 'cuda' 불가능 하면 'cpu'\n",
    "DEVICE = torch.device('cuda' if USE_CUDA else 'cpu')\n",
    "\n",
    "# 배치 사이즈 지정\n",
    "BATCH_SIZE = 256\n",
    "# 에포크 횟수 지정\n",
    "EPOCH = 30\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "# transforms.Compose 메서드는 이미지 데이터의 전처리, Augmentation 등의 과정에서 사용되는 메서드\n",
    "# transforms.Resize 메서드는 이미지의 크기를 조정\n",
    "# transforms.ToTensor 메서드는 이미지를 Tensor 형태로 변환하고 모든 값을 0에서 1사이로 정규화\n",
    "transform_base = transforms.Compose(\n",
    "    [transforms.Resize((64, 64)),\n",
    "     transforms.ToTensor()])\n",
    "\n",
    "# ImageFolder 메서드는 데이터셋을 불러오는 메서드\n",
    "# root 옵션에 데이터를 불러올 경로를 설정\n",
    "# transform 옵션에 데이터를 불러온 후 전처리 또는 Augmentation을 할 방법을 지정\n",
    "train_dataset = ImageFolder(root='.splitted/train', transform=transform_base)\n",
    "val_dataset = ImageFolder(root='.splitted/val', transform=transform_base)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# DataLoader는 불러온 이미지 데이터를 주어진 조건에 따라 미니 배치 단위로 분리하는 역할을 수행\n",
    "# shuffle=True로 설정하면 데이터의 순서가 섞여 모델이 학습을 할 떄 Label 정보의 순서를 기억하는 것을 방지\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4)\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=True,\n",
    "                        num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f315f74",
   "metadata": {},
   "source": [
    "## 베이스라인 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aa730c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-27T06:51:13.536478Z",
     "start_time": "2022-07-27T06:51:13.444664Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# 딥러닝 모델과 관련된 기본적인 함수를 포함하는 nn.Module 클래스를 상속하여 사용\n",
    "class Net(nn.Module):\n",
    "\n",
    "    # __init__ 함수에서 모델에서 사용할 모든 Layer를 정의\n",
    "    def __init__(self):\n",
    "        # nn.Module 내에 있는 메서드를 상속받아 사용\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # 첫 번째 2d Convolutional Layer 정의\n",
    "        # 파라미터는 순서대로 채널 수, 출력 채널 수, 커널 크기\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        # 2차원 MaxPooling을 실행하는 Layer 정의\n",
    "        # 파라미터는 순서대로 커널 크기, Stride\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # 입력 채널 32, 출력 채널 64, 커널 크기 3인 Convolutional Layer 정의\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        # 입력 채널 64, 출력 채널 64, 커널 크기 3인 Convolutional Layer 정의\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "\n",
    "        # Flatten 이후에 사용될 첫 번째 Fully Connected Layer 정의\n",
    "        self.fc1 = nn.Linear(4096, 512)\n",
    "        # Flatten 이후에 사용될 두 번째 Fully Connected Layer 정의\n",
    "        # fc1의 출력 채널 수와 동일하고, 모델에서 마지막 Layer로 사용될 것이기 때문에\n",
    "        # 출력 채널 수는 분류 클래스의 수와 동일\n",
    "        self.fc2 = nn.Linear(512, 33)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolution 연산을 진행한 후 Feature Map 생성\n",
    "        x = self.conv1(x)\n",
    "        # 생성된 Feature Map값에 비선형 활성 함수인 ReLU() 적용\n",
    "        x = F.relu(x)\n",
    "        # MaxPooling 적용\n",
    "        x = self.pool(x)\n",
    "        # 25%의 노드를 Dropout\n",
    "        # training=self.training 부분은 학습 모드일 때와 검증 모드일 때 각각 다르게 적용되기 위해 존대\n",
    "        # 학습 과정에서는 일부 노드를 랜덤하게 제외시키지만, 평가 과정에서는 모든 노드를 사용\n",
    "        x = F.dropout(x, p=0.25, training=self.training)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.dropout(x, p=0.25, training=self.training)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.dropout(x, p=0.25, training=self.training)\n",
    "\n",
    "        # 생성된 Feature Map을 1차원으로 펼치는 과정인 Flatten을 수행\n",
    "        x = x.view(-1, 4096)\n",
    "        # Flatten된 1차원 Tensor를 fc1에 적용\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        # 모델의 마지막 Layer\n",
    "        # 클래스의 개수에 해당하는 33개의 출력값을 가짐\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # 마지막 Layer의 33개의 결과값에 softmax() 함수를 적용하여 데이터가 각 클래스에 속할 확률을 Output값으로 출력\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "# 정의한 CNN 모델 Net()의 새로운 객체를 생성\n",
    "# to(DEVICE)를 통해 모델을 현재 사용 중인 장비에 할당\n",
    "model_base = Net()\n",
    "model_base = model_base.to(DEVICE)\n",
    "# optimizer는 Adam으로 설정하고, Learning Rate는 0.001로 설정\n",
    "optimizer = optim.Adam(model_base.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d8084e",
   "metadata": {},
   "source": [
    "## 모델 학습을 위한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "738cd2fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-27T06:51:13.552507Z",
     "start_time": "2022-07-27T06:51:13.538485Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer):\n",
    "    # 입력받는 모델을 학습 모드로 설정\n",
    "    model.train()\n",
    "    # train_loader에는 (data, target) 형태가 미니 배치 단위로 묶여 있음\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # data와 target 변수를 사용 중인 장비에 할당\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        # 이전 Batch의 Gradient값이 optimizer에 저장되어 있으므로 optimizer를 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 데이터를 모델에 입력하여 Output값을 계산\n",
    "        output = model(data)\n",
    "        # 모델에서 계산한 Output 값인 예측값과 Target 값 사이의 Loss를 계산\n",
    "        # 분류 문제에 적합한 Cross Entropy Loss를 사용\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        # 위에서 계산한 Loss 값을 바탕으로 Back Propagation을 통해 계산한 Gradient 값을 각 Parameter에 할당\n",
    "        loss.backward()\n",
    "        # 위에서 각 Parameter에 할당된 Gradient 값을 이용해 모델의 Parameter를 업데이트\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e90ccb",
   "metadata": {},
   "source": [
    "## 모델 평가를 위한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17daf048",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-27T06:51:13.568283Z",
     "start_time": "2022-07-27T06:51:13.554160Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    # 입력받는 모델을 평가 모드로 설정\n",
    "    model.eval()\n",
    "    # 미니 배치별로 Loss를 합산해서 저장할 변수인 test_loss를 정의\n",
    "    test_loss = 0\n",
    "    # 올바르게 예측한 데이터 수를 세는 변수인 correct를 정의\n",
    "    correct = 0\n",
    "\n",
    "    # 모델을 평가하는 단계에서는 모델의 Parameter를 업데이트하지 않아야 함\n",
    "    # with torch.no_grad() 메서드를 이용하여 해당 부분을 실행하는 동안 모델의 Parameter 업데이트를 중단\n",
    "    with torch.no_grad():\n",
    "        # 앞서 학습했던 것과 같이, test_loader에는 (data, target) 형태가 미니 배치단위로 묶여 있음\n",
    "        for data, target in test_loader:\n",
    "            # data, target 변수를 사용 중인 장비로 할당\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            # 데이터를 모델에 입력하여 output 값을 계산\n",
    "            output = model(data)\n",
    "\n",
    "            # 모델에서 계산한 output값인 예측값과 target 값 사이의 Loss를 계산\n",
    "            test_loss = F.cross_entropy(output, target, reduction='sum').item()\n",
    "\n",
    "            # 모델에 입력된 Test 데이터가 33개의 클래스에 속할 각각의 확률값이 Ouput으로 출력함\n",
    "            # 이 중 가장 높은 값을 가진 인덱스를 예측값으로 저장\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            # target.view_as(pred)를 통해 target Tensor의 구조를 pred Tensor와 같은 모양으로 정렬\n",
    "            # view_as() 메서드는 적용 대상 Tensor를 메서드에 입력되는 Tensor의 모양대로 재정렬하는 함수\n",
    "            # view() 함수는 정렬하고 싶은 Tensor의 모양을 숫자로 직접 지정한다는 점에서 차이가 있음\n",
    "            # eq() 메서드는 객체 간의 비교 연산자로, pred.eq(target.view_as(pred))은 pred와 target.view_as(pred)의 값이 일치하면 1, 일치하지 않으면 0을 반환\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        # 모든 미니 배치에서 합한 Loss값을 Batch 수로 나누어 미니 배치마다 계산된 Loss 값의 평균을 구함\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        # 모든 미니 배치에서 합한 정확도 값을 Batch 수로 나누어 미니 배치마다 게산된 정확도 값의 평균을 구함\n",
    "        test_accuracy = 100 * correct / len(test_loader.dataset)\n",
    "\n",
    "        # 측정한 Test Loss와 정확도를 반환\n",
    "        return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e160d50",
   "metadata": {},
   "source": [
    "## 모델 학습 실행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62fc7270",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-27T07:04:27.540039Z",
     "start_time": "2022-07-27T06:51:13.569479Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- epoch 1 ----------\n",
      "train Loss: 0.0154, Accuracy: 42.35%\n",
      "val Loss: 0.0129, Accuracy: 42.20%\n",
      "Completed in 0m 55s\n",
      "---------- epoch 2 ----------\n",
      "train Loss: 0.0097, Accuracy: 61.39%\n",
      "val Loss: 0.0085, Accuracy: 60.37%\n",
      "Completed in 0m 24s\n",
      "---------- epoch 3 ----------\n",
      "train Loss: 0.0063, Accuracy: 72.28%\n",
      "val Loss: 0.0054, Accuracy: 71.30%\n",
      "Completed in 0m 24s\n",
      "---------- epoch 4 ----------\n",
      "train Loss: 0.0054, Accuracy: 78.91%\n",
      "val Loss: 0.0044, Accuracy: 76.86%\n",
      "Completed in 0m 25s\n",
      "---------- epoch 5 ----------\n",
      "train Loss: 0.0044, Accuracy: 83.05%\n",
      "val Loss: 0.0040, Accuracy: 80.35%\n",
      "Completed in 0m 25s\n",
      "---------- epoch 6 ----------\n",
      "train Loss: 0.0032, Accuracy: 84.95%\n",
      "val Loss: 0.0051, Accuracy: 82.25%\n",
      "Completed in 0m 26s\n",
      "---------- epoch 7 ----------\n",
      "train Loss: 0.0025, Accuracy: 88.59%\n",
      "val Loss: 0.0031, Accuracy: 85.84%\n",
      "Completed in 0m 25s\n",
      "---------- epoch 8 ----------\n",
      "train Loss: 0.0030, Accuracy: 88.11%\n",
      "val Loss: 0.0032, Accuracy: 84.98%\n",
      "Completed in 0m 25s\n",
      "---------- epoch 9 ----------\n",
      "train Loss: 0.0030, Accuracy: 89.00%\n",
      "val Loss: 0.0032, Accuracy: 86.04%\n",
      "Completed in 0m 26s\n",
      "---------- epoch 10 ----------\n",
      "train Loss: 0.0018, Accuracy: 91.65%\n",
      "val Loss: 0.0035, Accuracy: 88.43%\n",
      "Completed in 0m 26s\n",
      "---------- epoch 11 ----------\n",
      "train Loss: 0.0029, Accuracy: 89.77%\n",
      "val Loss: 0.0024, Accuracy: 86.18%\n",
      "Completed in 0m 26s\n",
      "---------- epoch 12 ----------\n",
      "train Loss: 0.0023, Accuracy: 93.44%\n",
      "val Loss: 0.0015, Accuracy: 89.50%\n",
      "Completed in 0m 25s\n",
      "---------- epoch 13 ----------\n",
      "train Loss: 0.0014, Accuracy: 94.09%\n",
      "val Loss: 0.0025, Accuracy: 89.71%\n",
      "Completed in 0m 26s\n",
      "---------- epoch 14 ----------\n",
      "train Loss: 0.0018, Accuracy: 94.01%\n",
      "val Loss: 0.0024, Accuracy: 89.84%\n",
      "Completed in 0m 25s\n",
      "---------- epoch 15 ----------\n",
      "train Loss: 0.0013, Accuracy: 94.40%\n",
      "val Loss: 0.0014, Accuracy: 90.25%\n",
      "Completed in 0m 26s\n",
      "---------- epoch 16 ----------\n",
      "train Loss: 0.0013, Accuracy: 94.48%\n",
      "val Loss: 0.0024, Accuracy: 90.12%\n",
      "Completed in 0m 26s\n",
      "---------- epoch 17 ----------\n",
      "train Loss: 0.0017, Accuracy: 94.75%\n",
      "val Loss: 0.0021, Accuracy: 89.99%\n",
      "Completed in 0m 25s\n",
      "---------- epoch 18 ----------\n",
      "train Loss: 0.0015, Accuracy: 96.43%\n",
      "val Loss: 0.0024, Accuracy: 91.89%\n",
      "Completed in 0m 25s\n",
      "---------- epoch 19 ----------\n",
      "train Loss: 0.0006, Accuracy: 97.06%\n",
      "val Loss: 0.0013, Accuracy: 92.20%\n",
      "Completed in 0m 25s\n",
      "---------- epoch 20 ----------\n",
      "train Loss: 0.0010, Accuracy: 96.99%\n",
      "val Loss: 0.0022, Accuracy: 91.93%\n",
      "Completed in 0m 25s\n",
      "---------- epoch 21 ----------\n",
      "train Loss: 0.0008, Accuracy: 96.27%\n",
      "val Loss: 0.0012, Accuracy: 91.30%\n",
      "Completed in 0m 26s\n",
      "---------- epoch 22 ----------\n",
      "train Loss: 0.0007, Accuracy: 97.37%\n",
      "val Loss: 0.0007, Accuracy: 92.11%\n",
      "Completed in 0m 25s\n",
      "---------- epoch 23 ----------\n",
      "train Loss: 0.0006, Accuracy: 97.17%\n",
      "val Loss: 0.0025, Accuracy: 92.11%\n",
      "Completed in 0m 26s\n",
      "---------- epoch 24 ----------\n",
      "train Loss: 0.0007, Accuracy: 97.79%\n",
      "val Loss: 0.0004, Accuracy: 92.48%\n",
      "Completed in 0m 25s\n",
      "---------- epoch 25 ----------\n",
      "train Loss: 0.0005, Accuracy: 97.94%\n",
      "val Loss: 0.0014, Accuracy: 92.56%\n",
      "Completed in 0m 26s\n",
      "---------- epoch 26 ----------\n",
      "train Loss: 0.0004, Accuracy: 98.05%\n",
      "val Loss: 0.0019, Accuracy: 92.31%\n",
      "Completed in 0m 26s\n",
      "---------- epoch 27 ----------\n",
      "train Loss: 0.0006, Accuracy: 98.16%\n",
      "val Loss: 0.0013, Accuracy: 93.18%\n",
      "Completed in 0m 26s\n",
      "---------- epoch 28 ----------\n",
      "train Loss: 0.0005, Accuracy: 98.18%\n",
      "val Loss: 0.0018, Accuracy: 93.04%\n",
      "Completed in 0m 26s\n",
      "---------- epoch 29 ----------\n",
      "train Loss: 0.0007, Accuracy: 98.40%\n",
      "val Loss: 0.0007, Accuracy: 92.87%\n",
      "Completed in 0m 26s\n",
      "---------- epoch 30 ----------\n",
      "train Loss: 0.0006, Accuracy: 98.46%\n",
      "val Loss: 0.0011, Accuracy: 92.64%\n",
      "Completed in 0m 26s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "\n",
    "def train_baseline(model, train_loader, val_loader, optimizer, num_epochs=30):\n",
    "    # 정확도가 가장 높은 모델의 정확도를 저장하는 best_acc를 정의\n",
    "    best_acc = 0.0\n",
    "    # 정확도가 가장 높은 모델을 저장할 변수 best_model_wts를 선언\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # 한 Epoch당 소요되는 시간을 측정하기 위해 해당 Epoch을 시작할 때의 시간을 저장\n",
    "        since = time.time()\n",
    "        # 앞서 정의한 train() 함수를 이용하여 모델을 학습\n",
    "        train(model, train_loader, optimizer)\n",
    "        # 앞서 정의한 evaluate() 함수를 이용하여 해당 Epoch에서의 학습 Loss와 정확도를 계산\n",
    "        train_loss, train_acc = evaluate(model, train_loader)\n",
    "        # 앞서 정의한 evaluate() 함수를 이용하여 해당 Epoch에서의 검증 Loss와 정확도를 계산\n",
    "        val_loss, val_acc = evaluate(model, val_loader)\n",
    "\n",
    "        # 현재 Epoch의 검증 정확도가 최고 정확도보다 높다면\n",
    "        # best_acc를 현재 Epoch의 검증 정확도로 업데이트하고,\n",
    "        # 해당 Epoch의 모델을 best_model_wts에 저장\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        # 한 Epoch당 소요된 시간을 계산\n",
    "        time_elapsed = time.time() - since\n",
    "        print('---------- epoch {} ----------'.format(epoch))\n",
    "        # 해당 Epoch의 학습 Loss와 정확도를 출력\n",
    "        print('train Loss: {:.4f}, Accuracy: {:.2f}%'.format(\n",
    "            train_loss, train_acc))\n",
    "        # 해당 Epoch의 검증 Loss와 정확도를 출력\n",
    "        print('val Loss: {:.4f}, Accuracy: {:.2f}%'.format(val_loss, val_acc))\n",
    "        # 한 Epoch당 소요된 시간을 출력\n",
    "        print('Completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60,\n",
    "                                                    time_elapsed % 60))\n",
    "\n",
    "    # 최종적으로 정확도가 가장 높은 모델을 불러온 뒤, 반환\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "\n",
    "# 앞서 정의한 train_baseline() 함수를 이용하여 Baseline 모델을 학습\n",
    "base = train_baseline(model_base, train_loader, val_loader, optimizer, EPOCH)\n",
    "# 학습이 완료된 모델을 저장\n",
    "torch.save(base, 'baseline.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592e9394",
   "metadata": {},
   "source": [
    "## Transfer Learning\n",
    "\n",
    "- ResNet50 모델을 불러온 후, Fine-Tuning하여 작물 잎을 분류하는 주제에 맞추어 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dba55b",
   "metadata": {},
   "source": [
    "## Transfer Learning을 위한 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27fabf4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-27T07:12:41.209409Z",
     "start_time": "2022-07-27T07:12:41.083791Z"
    }
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize([64, 64]),\n",
    "        # 이미지를 무작위로 좌우 반전\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        # 이미지를 무작위로 상하 반전\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        # 이미지의 일부를 랜덤하게 잘라내어 52x52 사이즈로 변경\n",
    "        transforms.RandomCrop(52),\n",
    "        transforms.ToTensor(),\n",
    "        # 이미지가 Tensor 형태로 전환된 이후에 정규화를 시행\n",
    "        # 첫 번째 배열은 각각 Red, Green, Blue 채널 값에서 정규화를 적용할 평균값을 의미\n",
    "        # 두 번째 배열은 각각 Red, Green, Blue 채널 값에서 정규화를 적용할 표준편차 값을 의미\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize([64, 64]),\n",
    "        transforms.RandomCrop(52),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = '.splitted'\n",
    "image_datasets = {\n",
    "    x: ImageFolder(root=os.path.join(data_dir, x),\n",
    "                   transform=data_transforms[x])\n",
    "    for x in ['train', 'val']\n",
    "}\n",
    "dataloaders = {\n",
    "    x: DataLoader(image_datasets[x],\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  shuffle=True,\n",
    "                  num_workers=4)\n",
    "    for x in ['train', 'val']\n",
    "}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fc1dc2",
   "metadata": {},
   "source": [
    "## Pre-Trained Model 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a432d7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-27T07:12:42.672672Z",
     "start_time": "2022-07-27T07:12:42.317306Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "# resnet50 모델을 불러옴\n",
    "# pretrained 옵션을 True로 설정하면 미리 학습된 모델의 Parameter를 그대로 가져옴\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "# ResNet50 모델의 마지막 Layer의 출력 채널 수가 33개가 아님\n",
    "# 따라서 불러온 모델을 이 프로젝트의 맞추고자 모델의 마지막 Fully Connected Layer 대신 출력 채널의 수가 33개인 새로운 Layer를 추가할 것\n",
    "# 이를 위해 불러온 ResNet50에서 마지막 Layer의 입력 채널의 수를 저장\n",
    "num_ftrs = resnet.fc.in_features\n",
    "# 불러온 모델의 마지막 Fully Connected Layer를 새로운 Layer로 교체\n",
    "resnet.fc = nn.Linear(num_ftrs, 33)\n",
    "resnet = resnet.to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad,\n",
    "                                 resnet.parameters()),\n",
    "                          lr=0.001)\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# StepLR() 메서드는 Epoch에 따라 Learning Rate를 변경하는 역할을 함\n",
    "# step_size=7, gamma=0.1로 설정하면 7 Epoch마다 0.1씩 곱해 Learning Rate를 감소시킨다는 의미\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a3c7ba",
   "metadata": {},
   "source": [
    "## Pre-Trained Model의 일부 Layer Freeze하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3584207a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-27T07:12:43.295466Z",
     "start_time": "2022-07-27T07:12:43.277297Z"
    }
   },
   "outputs": [],
   "source": [
    "# 해당 Layer가 몇 번째 Layer인지를 나타내는 변수 ct 정의\n",
    "ct = 0\n",
    "# children() 메서드는 모델의 자식 모듈을 반복 가능한 객체로 반환\n",
    "# 여기서는 resnet 모델의 모든 Layer 정보를 담고 있음.\n",
    "for child in resnet.children():\n",
    "    # for 문을 한 번 반복한 후 다음 Layer를 지칭하기 위해 ct값 1증가\n",
    "    ct += 1\n",
    "    if ct < 6:\n",
    "        # ResNet50에 존재하는 10개의 Layer 중에서 1번부터 5번 Layer의 Parameter는 업데이트퇴지 않도록 고정하고,\n",
    "        # 6번부터 10번 Layer의 Parameter는 학습 과정에서 업데이트하도록 설정\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16b10db",
   "metadata": {},
   "source": [
    "## Transfer Learning 모델 학습과 검증을 위한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fbbaf4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-27T07:12:44.777915Z",
     "start_time": "2022-07-27T07:12:44.757642Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_resnet(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # 현재 진행 중인 epoch 출력\n",
    "        print('----------epoch {}----------'.format(epoch + 1))\n",
    "        since = time.time()\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            # 모든 데이터의 Loss를 합산해서 저장할 변수인 running_loss를 정의\n",
    "            running_loss = 0.0\n",
    "            # 올바르게 예측한 경위의 수를 세는 변수인 running_corrects를 정의\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                labels = labels.to(DEVICE)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 학습 단계에서만 모델의 Gradient를 업데이트\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                l_r = [x['lr'] for x in optimizer_ft.param_groups]\n",
    "                print('learning rate: ', l_r)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss,\n",
    "                                                       epoch_acc))\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60,\n",
    "                                                    time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # 정확도가 가장 높은 모델을 불러온 후 반환\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258b12c7",
   "metadata": {},
   "source": [
    "## 모델 학습 실행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b975366f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-27T07:28:15.976934Z",
     "start_time": "2022-07-27T07:12:47.044299Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------epoch 1----------\n",
      "learning rate:  [0.001]\n",
      "train Loss: 0.5954 Acc: 0.8186\n",
      "val Loss: 0.3328 Acc: 0.8919\n",
      "Completed in 0m 29s\n",
      "----------epoch 2----------\n",
      "learning rate:  [0.001]\n",
      "train Loss: 0.2217 Acc: 0.9302\n",
      "val Loss: 0.2543 Acc: 0.9199\n",
      "Completed in 0m 29s\n",
      "----------epoch 3----------\n",
      "learning rate:  [0.001]\n",
      "train Loss: 0.1865 Acc: 0.9410\n",
      "val Loss: 0.1970 Acc: 0.9367\n",
      "Completed in 0m 29s\n",
      "----------epoch 4----------\n",
      "learning rate:  [0.001]\n",
      "train Loss: 0.1324 Acc: 0.9557\n",
      "val Loss: 0.1508 Acc: 0.9546\n",
      "Completed in 0m 29s\n",
      "----------epoch 5----------\n",
      "learning rate:  [0.001]\n",
      "train Loss: 0.1244 Acc: 0.9596\n",
      "val Loss: 0.1585 Acc: 0.9513\n",
      "Completed in 0m 29s\n",
      "----------epoch 6----------\n",
      "learning rate:  [0.001]\n",
      "train Loss: 0.1098 Acc: 0.9647\n",
      "val Loss: 0.1238 Acc: 0.9601\n",
      "Completed in 0m 29s\n",
      "----------epoch 7----------\n",
      "learning rate:  [0.0001]\n",
      "train Loss: 0.0815 Acc: 0.9735\n",
      "val Loss: 0.0926 Acc: 0.9700\n",
      "Completed in 0m 29s\n",
      "----------epoch 8----------\n",
      "learning rate:  [0.0001]\n",
      "train Loss: 0.0446 Acc: 0.9857\n",
      "val Loss: 0.0476 Acc: 0.9842\n",
      "Completed in 0m 30s\n",
      "----------epoch 9----------\n",
      "learning rate:  [0.0001]\n",
      "train Loss: 0.0296 Acc: 0.9913\n",
      "val Loss: 0.0402 Acc: 0.9882\n",
      "Completed in 0m 31s\n",
      "----------epoch 10----------\n",
      "learning rate:  [0.0001]\n",
      "train Loss: 0.0255 Acc: 0.9916\n",
      "val Loss: 0.0400 Acc: 0.9880\n",
      "Completed in 0m 30s\n",
      "----------epoch 11----------\n",
      "learning rate:  [0.0001]\n",
      "train Loss: 0.0235 Acc: 0.9927\n",
      "val Loss: 0.0345 Acc: 0.9884\n",
      "Completed in 0m 29s\n",
      "----------epoch 12----------\n",
      "learning rate:  [0.0001]\n",
      "train Loss: 0.0178 Acc: 0.9941\n",
      "val Loss: 0.0320 Acc: 0.9896\n",
      "Completed in 0m 31s\n",
      "----------epoch 13----------\n",
      "learning rate:  [0.0001]\n",
      "train Loss: 0.0184 Acc: 0.9941\n",
      "val Loss: 0.0346 Acc: 0.9890\n",
      "Completed in 0m 32s\n",
      "----------epoch 14----------\n",
      "learning rate:  [1e-05]\n",
      "train Loss: 0.0183 Acc: 0.9939\n",
      "val Loss: 0.0363 Acc: 0.9884\n",
      "Completed in 0m 31s\n",
      "----------epoch 15----------\n",
      "learning rate:  [1e-05]\n",
      "train Loss: 0.0153 Acc: 0.9945\n",
      "val Loss: 0.0317 Acc: 0.9884\n",
      "Completed in 0m 30s\n",
      "----------epoch 16----------\n",
      "learning rate:  [1e-05]\n",
      "train Loss: 0.0146 Acc: 0.9953\n",
      "val Loss: 0.0340 Acc: 0.9900\n",
      "Completed in 0m 31s\n",
      "----------epoch 17----------\n",
      "learning rate:  [1e-05]\n",
      "train Loss: 0.0151 Acc: 0.9955\n",
      "val Loss: 0.0309 Acc: 0.9902\n",
      "Completed in 0m 32s\n",
      "----------epoch 18----------\n",
      "learning rate:  [1e-05]\n",
      "train Loss: 0.0148 Acc: 0.9952\n",
      "val Loss: 0.0288 Acc: 0.9909\n",
      "Completed in 0m 31s\n",
      "----------epoch 19----------\n",
      "learning rate:  [1e-05]\n",
      "train Loss: 0.0139 Acc: 0.9957\n",
      "val Loss: 0.0299 Acc: 0.9902\n",
      "Completed in 0m 31s\n",
      "----------epoch 20----------\n",
      "learning rate:  [1e-05]\n",
      "train Loss: 0.0120 Acc: 0.9960\n",
      "val Loss: 0.0306 Acc: 0.9899\n",
      "Completed in 0m 33s\n",
      "----------epoch 21----------\n",
      "learning rate:  [1.0000000000000002e-06]\n",
      "train Loss: 0.0136 Acc: 0.9953\n",
      "val Loss: 0.0310 Acc: 0.9905\n",
      "Completed in 0m 36s\n",
      "----------epoch 22----------\n",
      "learning rate:  [1.0000000000000002e-06]\n",
      "train Loss: 0.0124 Acc: 0.9959\n",
      "val Loss: 0.0334 Acc: 0.9889\n",
      "Completed in 0m 34s\n",
      "----------epoch 23----------\n",
      "learning rate:  [1.0000000000000002e-06]\n",
      "train Loss: 0.0126 Acc: 0.9956\n",
      "val Loss: 0.0325 Acc: 0.9895\n",
      "Completed in 0m 34s\n",
      "----------epoch 24----------\n",
      "learning rate:  [1.0000000000000002e-06]\n",
      "train Loss: 0.0131 Acc: 0.9954\n",
      "val Loss: 0.0325 Acc: 0.9909\n",
      "Completed in 0m 33s\n",
      "----------epoch 25----------\n",
      "learning rate:  [1.0000000000000002e-06]\n",
      "train Loss: 0.0135 Acc: 0.9954\n",
      "val Loss: 0.0324 Acc: 0.9894\n",
      "Completed in 0m 32s\n",
      "----------epoch 26----------\n",
      "learning rate:  [1.0000000000000002e-06]\n",
      "train Loss: 0.0125 Acc: 0.9960\n",
      "val Loss: 0.0291 Acc: 0.9899\n",
      "Completed in 0m 31s\n",
      "----------epoch 27----------\n",
      "learning rate:  [1.0000000000000002e-06]\n",
      "train Loss: 0.0128 Acc: 0.9959\n",
      "val Loss: 0.0321 Acc: 0.9896\n",
      "Completed in 0m 32s\n",
      "----------epoch 28----------\n",
      "learning rate:  [1.0000000000000002e-07]\n",
      "train Loss: 0.0115 Acc: 0.9964\n",
      "val Loss: 0.0322 Acc: 0.9894\n",
      "Completed in 0m 31s\n",
      "----------epoch 29----------\n",
      "learning rate:  [1.0000000000000002e-07]\n",
      "train Loss: 0.0122 Acc: 0.9960\n",
      "val Loss: 0.0319 Acc: 0.9894\n",
      "Completed in 0m 32s\n",
      "----------epoch 30----------\n",
      "learning rate:  [1.0000000000000002e-07]\n",
      "train Loss: 0.0123 Acc: 0.9960\n",
      "val Loss: 0.0301 Acc: 0.9905\n",
      "Completed in 0m 30s\n",
      "Best val Acc: 0.990862\n"
     ]
    }
   ],
   "source": [
    "# 앞서 정의한 train_resnet() 함수를 이용하여 Fine-Tuning\n",
    "model_resnet50 = train_resnet(resnet,\n",
    "                              criterion,\n",
    "                              optimizer_ft,\n",
    "                              exp_lr_scheduler,\n",
    "                              num_epochs=EPOCH)\n",
    "# 학습이 완료된 모델을 저장\n",
    "torch.save(model_resnet50, 'resnet50.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6c01e0",
   "metadata": {},
   "source": [
    "## 베이스라인 모델 평가를 위한 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa2e6d83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-27T07:28:28.964457Z",
     "start_time": "2022-07-27T07:28:28.909854Z"
    }
   },
   "outputs": [],
   "source": [
    "# 베이스라인 모델의 성능을 평가하기 위해 DataLoader를 생성\n",
    "# 모델을 학습시킬 때 사용한 학습, 검증 데이터와 동일한 방법으로 전처리를 수행\n",
    "transform_base = transforms.Compose(\n",
    "    [transforms.Resize([64, 64]),\n",
    "     transforms.ToTensor()])\n",
    "test_base = ImageFolder(root='.splitted/test', transform=transform_base)\n",
    "test_loader_base = DataLoader(test_base,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9208474",
   "metadata": {},
   "source": [
    "## Transfer Learning 모델 평가를 위한 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "392e0493",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-27T07:28:31.382392Z",
     "start_time": "2022-07-27T07:28:31.343849Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transfer Learning 모델의 성능 평가를 위해 사용할 테스트 데이터의 DataLoader를 생성\n",
    "# 모델을 학습시킬 때 사용한 학습, 검증 데이터와 동일한 방법으로 전처리 수행\n",
    "transform_resNet = transforms.Compose([\n",
    "    transforms.Resize([64, 64]),\n",
    "    transforms.RandomCrop(52),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "test_resNet = ImageFolder(root='.splitted/test', transform=transform_resNet)\n",
    "test_loader_resNet = DataLoader(test_resNet,\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                shuffle=True,\n",
    "                                num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc312331",
   "metadata": {},
   "source": [
    "## 베이스라인 모델 성능 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43f3a446",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-27T07:28:47.053177Z",
     "start_time": "2022-07-27T07:28:33.341495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline test acc:  93.00287895856803\n"
     ]
    }
   ],
   "source": [
    "# 저장했던 베이스라인 모델 불러오기\n",
    "baseline = torch.load('baseline.pt')\n",
    "# 모델을 평가 모드로 설정\n",
    "baseline.eval()\n",
    "# 테스트 데이터에 대한 정확도를 측정\n",
    "test_loss, test_accuracy = evaluate(baseline, test_loader_base)\n",
    "\n",
    "print('baseline test acc: ', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f685ae9",
   "metadata": {},
   "source": [
    "## Transfer Learning 모델 성능 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f3cc855",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-27T07:29:02.593043Z",
     "start_time": "2022-07-27T07:28:55.686895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet test acc:  98.96107147327575\n"
     ]
    }
   ],
   "source": [
    "# 저장했던 Transfer Learning 모델 불러오기\n",
    "resnet50 = torch.load('resnet50.pt')\n",
    "# 모델을 평가 모드로 설정\n",
    "resnet50.eval()\n",
    "# 테스트 데이터에 대한 정확도를 측정\n",
    "test_loss, test_accuracy = evaluate(resnet50, test_loader_resNet)\n",
    "\n",
    "print('ResNet test acc: ', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595d594a",
   "metadata": {},
   "source": [
    "미리 학습된 모델을 불러와 일부를 Fine-Tuning하는 것이 더 높은 예측 성능\n",
    "\n",
    "<br />\n",
    "\n",
    "Pre-Trained 모델은 약 1,400만 개의 이미지를 학습해놓은 모델이고, 이 모델에는 다양한 이미지의 Feature가 학습되어 있음\n",
    "\n",
    "<br />\n",
    "\n",
    "따라서 Pre-Trained Model이 더 좋은 성능을 나타낼 가능성이 높다는 것은 매우 당연한 사실"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
